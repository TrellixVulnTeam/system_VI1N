==== Kafka

===== kafka使用

.删除topic
----
kafka-topics.sh --delete --zookeeper hadoop01:2181 hadoop02:2181 hadoop03:2181 --topic
----

.修改topic的offset
----
kafka-consumer-groups.sh --bootstrap-server 192.168.102.12:9092 --group rtd --reset-offsets --topic rtdReceive --to-offset 0 --execute
----

.查询消费组
----
kafka-consumer-groups.sh --bootstrap-server {kafka连接地址} --list
----

.删除消费组
----
kafka-consumer-groups.sh --bootstrap-server {kafka连接地址} --delete --group {消费组}
----

.查看topic详细信息
----
kafka-topics.sh -zookeeper hadoop01:2181 hadoop02:2181 hadoop03:2181 -describe -topic dping
----

.列出所有topic
----
kafka-topics.sh --list --zookeeper hadoop01:2181 hadoop02:2181 hadoop03:2181
----

.发送消息
----
kafka-console-producer.sh --broker-list hadoop01:9092 hadoop02:9092 hadoop03:9092 --topic dping
----

.查看消费组的消费情况
----
kafka-consumer-groups.sh --bootstrap-server hadoop01:9092 --describe --group thcl-consumer-group
----

.创建topic
----
kafka-topics.sh --create --zookeeper hadoop01:2181 hadoop02:2181 hadoop03:2181 --replication-factor 4 --partitions 6 --topic test4replic
----

.kafka单节点启动
----
kafka-server-start.sh -daemon /data/software/kafka_2.13-2.7.0/config/server.properties
----

[NOTE]
Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。 +
Topic：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。 +
Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。 +
Segment：partition物理上由多个segment组成，下面2.2和2.3有详细说明。 +
offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。 partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息.

.创建topic
----
kafka-topics.sh –zookeeper localhost:2181 –create –topic my-topic –partitions 1 –replication-factor 1 –config max.message.bytes=64000 –config flush.messages=1
----

.创建topic后修改topic参数
----
kafka-configs.sh –zookeeper localhost:2181 –entity-type topics –entity-name my-topic –alter –add-config max.message.bytes=128000
----

.查看topic的offset情况

----
kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list hadoop01:9092 --topic realTimeData
----

.查看consumer group列表

----
kafka-consumer-groups.sh  --bootstrap-server hadoop01:9092 --list
----

.查看分区情况，节点信息，复制情况

----
kafka-topics.sh  --topic realTimeData --describe --zookeeper hadoop01:2181 hadoop02:2181 hadoop03:2181
----

kafka修改topic的副本数
[source,bash]
----
需要新建json文件increase-replication-factor.json
{
	"version": 1,
	"partitions": [{
			"topic": "aaad",
			"partition": 0,
			"replicas": [1, 3]
		},
		{
			"topic": "aaad",
			"partition": 1,
			"replicas": [1, 2]
		},
		{
			"topic": "aaad",
			"partition": 2,
			"replicas": [2, 3]
		},
		{
			"topic": "aaad",
			"partition": 3,
			"replicas": [2, 3]
		},
		{
			"topic": "aaad",
			"partition": 4,
			"replicas": [1, 3]
		},
		{
			"topic": "aaad",
			"partition": 5,
			"replicas": [1, 2]
		}
	]
}
然后执行命令
kafka-reassign-partitions.sh --zookeeper node01:2181 node02:2181 node03:2181  --reassignment-json-file increase-replication-factor.json --execute --additional
----


===== 配置
